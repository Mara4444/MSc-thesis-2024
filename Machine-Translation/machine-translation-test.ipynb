{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maras\\anaconda3\\envs\\llama\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [02:00<00:00, 40.12s/it]\n"
     ]
    }
   ],
   "source": [
    "# download machine translation model\n",
    "model_name = \"facebook/nllb-200-3.3B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(name,lang):\n",
    "    \"\"\"\n",
    "    Loads a dataset from huggingface in the requested language.\n",
    "    \n",
    "    Parameters:\n",
    "    name: name of the dataset ['mgsm', 'xcopa', 'xstorycloze', 'mkqa', 'pawsx', 'xnli' or 'xlsum']\n",
    "    lang: language of the dataset to load.\n",
    "    \n",
    "    Returns:\n",
    "    Dataset in the specified language.\n",
    "    \"\"\"\n",
    "    if name == \"mgsm\":\n",
    "        dataset = load_dataset(\"juletxara/mgsm\",lang) \n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    elif name == \"xcopa\" and lang == \"en\":\n",
    "        dataset = load_dataset(\"pkavumba/balanced-copa\")\n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    elif name == \"xcopa\":\n",
    "        dataset = load_dataset(\"xcopa\",lang) \n",
    "        \n",
    "        return dataset \n",
    "    \n",
    "    elif name == \"xstorycloze\":\n",
    "        dataset = load_dataset(\"juletxara/xstory_cloze\",lang)   \n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    elif name == \"mkqa\":\n",
    "        dataset = load_dataset(\"mkqa\")\n",
    "        \n",
    "        if lang in dataset[\"train\"][\"queries\"][0].keys():\n",
    "            questionlist = [language[lang] for language in dataset[\"train\"][\"queries\"]]\n",
    "            answerlist = [language[lang] for language in dataset[\"train\"][\"answers\"]]\n",
    "            \n",
    "            dataset = {\n",
    "                \"train\": {\n",
    "                    \"queries\": questionlist,\n",
    "                    \"answers\": answerlist,\n",
    "                }\n",
    "            }\n",
    "\n",
    "            return dataset\n",
    "        \n",
    "        else:\n",
    "            print(\"Language not found. Specify one of the following languages: ['ar', 'da', 'de', 'en', 'es', 'fi', 'fr', 'he', 'hu', 'it','ja', 'km', 'ko', 'ms', 'nl', 'no', 'pl', 'pt', 'ru', 'sv', 'th', 'tr', 'vi', 'zh'\")\n",
    "    \n",
    "    elif name == \"pawsx\":\n",
    "        dataset = load_dataset(\"paws-x\",lang)    \n",
    "\n",
    "        return dataset\n",
    "    \n",
    "    elif name == \"xnli\":\n",
    "        dataset = load_dataset(\"xnli\",lang)  \n",
    "\n",
    "        return dataset\n",
    "    \n",
    "    elif name == \"xlsum\":        \n",
    "        dataset = load_dataset(\"csebuetnlp/xlsum\",lang) # ['amharic', 'arabic', 'azerbaijani', 'bengali', 'burmese', 'chinese_simplified', 'chinese_traditional', 'english', 'french', 'gujarati', 'hausa', 'hindi', 'igbo', 'indonesian', 'japanese', 'kirundi', 'korean', 'kyrgyz', 'marathi', 'nepali', 'oromo', 'pashto', 'persian', 'pidgin', 'portuguese', 'punjabi', 'russian', 'scottish_gaelic', 'serbian_cyrillic', 'serbian_latin', 'sinhala', 'somali', 'spanish', 'swahili', 'tamil', 'telugu', 'thai', 'tigrinya', 'turkish', 'ukrainian', 'urdu', 'uzbek', 'vietnamese', 'welsh', 'yoruba']\n",
    "\n",
    "        return dataset\n",
    "    \n",
    "    else:\n",
    "        print(\"Dataset name is not correctly specified. Please input 'mgsm', 'xcopa', 'xstorycloze', 'mkqa', 'pawsx', 'xnli' or 'xlsum'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = ['This is the sentence to translate.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_list(input_list,src_lang,trg_lang):\n",
    "    \"\"\"\n",
    "    Translate a list from the source language to the target language.\n",
    "    \n",
    "    Parameters:\n",
    "    input_list: input list of strings to translate.\n",
    "    src_lang: language of input string given in iso2-code.\n",
    "    trg_lang: target language given in iso2-code.\n",
    "    \n",
    "    Returns:\n",
    "    Translated list of strings.\n",
    "    \"\"\"\n",
    "    translated_list = []\n",
    "    translator = pipeline(\n",
    "        'translation', \n",
    "        model=model, \n",
    "        tokenizer=tokenizer\n",
    "        )\n",
    "    \n",
    "    for string in input_list:\n",
    "        output = translator(string, \n",
    "                            src_lang=src_lang, \n",
    "                            tgt_lang=trg_lang\n",
    "                            )\n",
    "        translated_text = output[0]['translation_text']\n",
    "        print(translated_text)\n",
    "        translated_list.append(translated_text)\n",
    "        # translated_list.append('test')\n",
    "    \n",
    "    return translated_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the sentence to translate.\n",
      "[{'translation_text': ''}]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_list(input_list,\"en\",\"nl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_dataset(dataset,name,src_lang,trg_lang): # not possible to replace values of databaseDict in place.. so output as pandas df?\n",
    "    \"\"\"\n",
    "    Translate a dataset from the source language to the target language.\n",
    "    \n",
    "    Parameters:\n",
    "    dataset: dataset to translate.\n",
    "    name: name of the dataset ['mgsm', 'xcopa', 'xstorycloze', 'mkqa', 'pawsx', 'xnli' or 'xlsum']\n",
    "    src_lang: language of input string given in iso2-code.\n",
    "    trg_lang: target language given in iso2-code.\n",
    "    \n",
    "    Returns:\n",
    "    Translated dataset and returns as DataFrame. \n",
    "    \"\"\"\n",
    "    if name  == 'mgsm': \n",
    "        \n",
    "        translated1_list = translate_list(dataset[\"test\"][\"question\"],src_lang,trg_lang)\n",
    "\n",
    "        translated_dataset = pd.DataFrame({'question': translated1_list,\n",
    "                                           'answer_number': dataset[\"test\"][\"answer_number\"]\n",
    "                                           })\n",
    "        return translated_dataset   \n",
    "      \n",
    "    elif name  == 'xcopa': \n",
    "        \n",
    "        translated1_list = translate_list(dataset[\"test\"][\"premise\"],src_lang,trg_lang)\n",
    "        translated2_list = translate_list(dataset[\"test\"][\"question\"],src_lang,trg_lang)\n",
    "        translated3_list = translate_list(dataset[\"test\"][\"choice1\"],src_lang,trg_lang)\n",
    "        translated4_list = translate_list(dataset[\"test\"][\"choice2\"],src_lang,trg_lang)\n",
    "\n",
    "        translated_dataset = pd.DataFrame({'premise': translated1_list,\n",
    "                                           'question': translated2_list,\n",
    "                                           'choice1': translated3_list,\n",
    "                                           'choice2': translated4_list, \n",
    "                                           'label': dataset[\"test\"][\"label\"]\n",
    "                                           })\n",
    "        return translated_dataset\n",
    "    \n",
    "    elif name  == 'xstorycloze': \n",
    "\n",
    "        translated1_list = translate_list(dataset[\"eval\"][\"input_sentence_1\"],src_lang,trg_lang)\n",
    "        translated2_list = translate_list(dataset[\"eval\"][\"input_sentence_2\"],src_lang,trg_lang)\n",
    "        translated3_list = translate_list(dataset[\"eval\"][\"input_sentence_3\"],src_lang,trg_lang)\n",
    "        translated4_list = translate_list(dataset[\"eval\"][\"input_sentence_4\"],src_lang,trg_lang)\n",
    "        translated5_list = translate_list(dataset[\"eval\"][\"sentence_quiz1\"],src_lang,trg_lang)\n",
    "        translated6_list = translate_list(dataset[\"eval\"][\"sentence_quiz2\"],src_lang,trg_lang)\n",
    "        \n",
    "        translated_dataset = pd.DataFrame({'input_sentence_1': translated1_list,\n",
    "                                           'input_sentence_2': translated2_list,\n",
    "                                           'input_sentence_3': translated3_list,\n",
    "                                           'input_sentence_4': translated4_list, \n",
    "                                           'sentence_quiz1': translated5_list,\n",
    "                                           'sentence_quiz1': translated6_list,\n",
    "                                           'answer_right_ending': dataset[\"eval\"][\"answer_right_ending\"]\n",
    "                                           })\n",
    "        return translated_dataset\n",
    "    \n",
    "    # elif name == \"mkqa\":\n",
    "    # answer column is in this shape: [{'type': 5, 'entity': '', 'text': '11.0 years', 'aliases': ['11 years']}]\n",
    "    # how to translate only text and aliases and keep the rest of the structure?\n",
    "\n",
    "    elif name  == 'pawsx': \n",
    "        \n",
    "        translated1_list = translate_list(dataset[\"test\"][\"sentence1\"],src_lang,trg_lang)\n",
    "        translated2_list = translate_list(dataset[\"test\"][\"sentence2\"],src_lang,trg_lang)\n",
    "\n",
    "        translated_dataset = pd.DataFrame({'sentence1': translated1_list,\n",
    "                                           'sentence2': translated2_list,\n",
    "                                           'label': dataset[\"test\"][\"label\"]\n",
    "                                           })\n",
    "        return translated_dataset\n",
    "    \n",
    "    elif name  == 'xnli': \n",
    "        \n",
    "        translated1_list = translate_list(dataset[\"test\"][\"premise\"],src_lang,trg_lang)\n",
    "        translated2_list = translate_list(dataset[\"test\"][\"hypothesis\"],src_lang,trg_lang)\n",
    "\n",
    "        translated_dataset = pd.DataFrame({'premise': translated1_list,\n",
    "                                           'hypothesis': translated2_list,\n",
    "                                           'label': dataset[\"test\"][\"label\"]\n",
    "                                           })\n",
    "        return translated_dataset\n",
    "    \n",
    "    elif name  == 'xlsum': \n",
    "        \n",
    "        translated1_list = translate_list(dataset[\"test\"][\"title\"],src_lang,trg_lang)\n",
    "        translated2_list = translate_list(dataset[\"test\"][\"summary\"],src_lang,trg_lang)\n",
    "        translated3_list = translate_list(dataset[\"test\"][\"text\"],src_lang,trg_lang)\n",
    "\n",
    "        translated_dataset = pd.DataFrame({'title': translated1_list,\n",
    "                                           'summary': translated2_list,\n",
    "                                           'text': translated3_list\n",
    "                                           })\n",
    "        return translated_dataset\n",
    "\n",
    "    else:\n",
    "        print(\"Dataset name is not correctly specified. Please input 'mgsm', 'xcopa', 'xstorycloze', 'mkqa', 'pawsx', 'xnli' or 'xlsum'.\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"mgsm\"\n",
    "dataset = get_dataset(name,\"en\")\n",
    "translate_dataset(dataset,name,\"en\",\"nl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_string(string,src_lang,trg_lang):\n",
    "    \"\"\"\n",
    "    Translate a single string from the source language to the target language.\n",
    "    \n",
    "    Parameters:\n",
    "    string: input string to translate.\n",
    "    src_lang: language of input string given in iso2-code.\n",
    "    trg_lang: target language given in iso2-code.\n",
    "    \n",
    "    Returns:\n",
    "    Translated string.\n",
    "    \"\"\"\n",
    "    translator = pipeline(\n",
    "        'translation', \n",
    "        model=model, \n",
    "        tokenizer=tokenizer, \n",
    "        src_lang=src_lang, \n",
    "        tgt_lang=trg_lang, \n",
    "        max_length = 400\n",
    "        )\n",
    "\n",
    "    output = translator(string)\n",
    "    translated_text = output[0]['translation_text']\n",
    "    \n",
    "    return translated_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
